# ğŸ¤– Personal AI Agent â€” Android App

> A powerful, privacy-first AI assistant for Android that understands natural language commands in **Hindi and English** and controls your phone.

---

## ğŸ“± App Overview

**Personal AI Agent** lets you control your Android phone using natural language. Type or speak commands like:
- *"WhatsApp kholo"* â†’ Opens WhatsApp
- *"YouTube pe cooking videos search karo"* â†’ Searches YouTube
- *"Set alarm at 7 AM"* â†’ Sets an alarm
- *"Call 9876543210"* â†’ Opens the dialer
- *"Google par weather search karo"* â†’ Searches browser

The AI understands your intent, converts it to a structured action, and executes it â€” all **without any backend server**. Your API key is stored encrypted on your device only.

---

## ğŸ—ï¸ Project Structure

```
PersonalAIAgent/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ src/main/
â”‚       â”œâ”€â”€ AndroidManifest.xml
â”‚       â””â”€â”€ java/com/personalaiagent/
â”‚           â”œâ”€â”€ MainActivity.kt                    # Entry point
â”‚           â”œâ”€â”€ model/
â”‚           â”‚   â””â”€â”€ Models.kt                      # Data models, AIAction, etc.
â”‚           â”œâ”€â”€ data/
â”‚           â”‚   â”œâ”€â”€ SecureStorage.kt               # Encrypted API key storage
â”‚           â”‚   â””â”€â”€ AIRepository.kt                # AI API communication
â”‚           â”œâ”€â”€ service/
â”‚           â”‚   â”œâ”€â”€ ActionExecutor.kt              # Executes device actions
â”‚           â”‚   â””â”€â”€ VoiceService.kt                # STT + TTS
â”‚           â”œâ”€â”€ viewmodel/
â”‚           â”‚   â”œâ”€â”€ MainViewModel.kt               # Main screen state
â”‚           â”‚   â””â”€â”€ SettingsViewModel.kt           # Settings screen state
â”‚           â””â”€â”€ ui/
â”‚               â”œâ”€â”€ navigation/
â”‚               â”‚   â””â”€â”€ AppNavigation.kt           # Nav graph
â”‚               â”œâ”€â”€ screens/
â”‚               â”‚   â”œâ”€â”€ MainScreen.kt              # Main chat UI
â”‚               â”‚   â””â”€â”€ SettingsScreen.kt          # API key config
â”‚               â”œâ”€â”€ components/
â”‚               â”‚   â””â”€â”€ Components.kt              # Reusable composables
â”‚               â””â”€â”€ theme/
â”‚                   â”œâ”€â”€ Theme.kt                   # Dark theme colors
â”‚                   â””â”€â”€ Typography.kt              # Text styles
â”‚   â””â”€â”€ res/
â”‚       â””â”€â”€ values/
â”‚           â”œâ”€â”€ strings.xml
â”‚           â””â”€â”€ themes.xml
â”œâ”€â”€ build.gradle
â””â”€â”€ settings.gradle
```

---

## ğŸš€ Features

### âœ… Phase 1 (Implemented)

| Feature | Description |
|---------|-------------|
| ğŸ™ï¸ Voice Input | Speech-to-text with Hindi + English support |
| ğŸ”Š Voice Output | TTS reads AI responses aloud |
| ğŸ“± Open Apps | Launch any installed app by name |
| â–¶ï¸ YouTube Search | Search YouTube directly |
| ğŸŒ Browser Search | Google search via browser |
| ğŸ“ Dial Numbers | Open dialer with number |
| ğŸ’¬ Draft SMS | Open SMS with pre-filled content |
| â° Set Alarm | Create alarms via AlarmClock API |
| ğŸ”” Set Reminder | Create reminders/events |
| ğŸ” Secure API Key | AES-256 encrypted storage via Android Keystore |
| âš ï¸ Confirmation Dialog | User must confirm calls/SMS before execution |
| ğŸ“‹ Activity Log | Full history of executed commands |
| ğŸŒ™ Dark Mode | Sleek dark UI by default |

### ğŸ”® Phase 2 (Architecture Ready)

- Accessibility Service for advanced automation
- Screen content reading
- Auto-typing and screen interaction
- App usage analytics
- Multi-language expansion

---

## ğŸ”Œ Supported AI Providers

| Provider | Models | Get API Key |
|----------|--------|-------------|
| **OpenAI** | GPT-4o-mini, GPT-4o, GPT-3.5-turbo | platform.openai.com |
| **Anthropic** | Claude Haiku, Sonnet, Opus | console.anthropic.com |
| **Google** | Gemini Pro | makersuite.google.com |
| **Groq** | Llama3, Mixtral (free tier!) | console.groq.com |

> ğŸ’¡ **Tip:** Start with **Groq** â€” it's free, very fast, and works great for this use case.

---

## ğŸ”’ Privacy & Security

- âœ… **No backend server** â€” App talks directly to AI provider
- âœ… **Encrypted storage** â€” API keys stored with AES-256-GCM via Android Keystore
- âœ… **No data collection** â€” Nothing sent to any third party except your AI provider
- âœ… **On-device processing** â€” All logic runs locally
- âœ… **Confirmation required** â€” Calls and SMS need explicit user approval

---

## ğŸ› ï¸ How It Works

```
User Input (text/voice)
        â†“
  VoiceService (STT)
        â†“
  MainViewModel
        â†“
  AIRepository.processCommand()
        â†“
  AI Provider API (user's key)
        â†“
  Parse JSON Response â†’ AIAction
        â†“
  [Confirmation if sensitive]
        â†“
  ActionExecutor.execute()
        â†“
  Device Action (open app, dial, etc.)
        â†“
  VoiceService.speak() + Activity Log
```

---

## âš™ï¸ Setup & Build

### Requirements
- Android Studio Hedgehog (2023.1.1) or newer
- Android SDK 34
- Kotlin 1.9.10
- Min Android: API 26 (Android 8.0)

### Build Steps

```bash
# 1. Clone / open project in Android Studio
# 2. Sync Gradle dependencies
# 3. Build & run on device/emulator (API 26+)
```

### First Time Setup

1. Open app â†’ tap âš™ï¸ Settings
2. Select your AI Provider (try Groq for free!)
3. Paste your API key
4. Tap **Test API Key** to verify
5. Tap **Save Settings**
6. Return to main screen and start commanding!

---

## ğŸ§© Adding New Actions

To add a new action type:

1. **Add constant** in `ActionTypes` object in `Models.kt`:
   ```kotlin
   const val MY_NEW_ACTION = "my_new_action"
   ```

2. **Update AI system prompt** in `AIRepository.kt` to teach the AI about the new action.

3. **Add executor** in `ActionExecutor.kt`:
   ```kotlin
   ActionTypes.MY_NEW_ACTION -> myNewAction(action)
   ```

4. **Add icon** in `getActionIcon()` in `MainScreen.kt`.

---

## ğŸ“‹ JSON Action Format

The AI always returns structured JSON like this:

```json
{
  "action": "open_app",
  "target": "WhatsApp",
  "query": "",
  "extras": {},
  "response": "WhatsApp à¤–à¥‹à¤² à¤°à¤¹à¤¾ à¤¹à¥‚à¤‚!"
}
```

```json
{
  "action": "set_alarm",
  "target": "",
  "query": "Morning Alarm",
  "extras": { "hour": "7", "minute": "30" },
  "response": "Setting alarm for 7:30 AM!"
}
```

---

## ğŸ¨ UI Design

- **Default:** Dark mode with purple accent (`#7C4DFF`)
- **Framework:** Jetpack Compose with Material3
- **Layout:** Single-column with bottom input bar
- **Activity log:** Reverse-chronological card list
- **Animations:** Pulse effect on mic, smooth transitions

---

## ğŸ”® Future Expansion: Accessibility Mode

To enable advanced screen automation (typing, clicking, reading screen content), add an Accessibility Service:

```kotlin
// In AndroidManifest.xml:
<service
    android:name=".service.AgentAccessibilityService"
    android:permission="android.permission.BIND_ACCESSIBILITY_SERVICE">
    <intent-filter>
        <action android:name="android.accessibilityservice.AccessibilityService"/>
    </intent-filter>
    <meta-data
        android:name="android.accessibilityservice"
        android:resource="@xml/accessibility_service_config"/>
</service>
```

This unlocks: screen reading, auto-fill, UI navigation, app content extraction â€” enabling true Siri/Google Assistant level automation.

---

## ğŸ“¦ Dependencies

```gradle
// Core Compose + Material3
// Navigation Compose
// EncryptedSharedPreferences (Security Crypto)
// OkHttp + Retrofit (API calls)
// Gson (JSON parsing)
// Accompanist Permissions
// Kotlin Coroutines
// Core Splash Screen
```

---

## ğŸ“œ License

MIT License â€” Free to use, modify, and distribute.

---

*Built with â¤ï¸ for the future of AI-powered mobile assistants.*
